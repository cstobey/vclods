function etl_sync_tbl { # PRIVATE
# TODO: generate a subselect the same as with the odku case so #generate_unique works... ie, use an actual subselect that is JOINed.
  grep -E "#([^ ]+\s+$1(\s|$)|explode)" <<<"$working_fields" | awk -v t="${1%%@*}" -v tt="$tmp_tbl" -f etl_main
}
function etl_populate_tmp_tbl { # PRIVATE
  [ "$ETL_EXT_ROW_REP" -eq 1 ] && echo "SET SESSION binlog_format='ROW';"
  cat - "$TEMP_FILE" << EOF  # sed gets rid of directives to avoid confusing other potential stream readers
$(sed '/^ *#/ d;s/#.*$//' "$ETL_TBL_TEMP_FILE")
#RESET
#start INSERT INTO $tmp_tbl ($ingest_fields) VALUES
EOF
}
function etl_explode_extra_tbls_using_sql { # PRIVATE
  grep '#explode_json_deep' -q <<<"$working_fields" && echo 'SET SESSION standard_compliant_cte = 0;'
  grep '#explode' <<<"$working_fields" | awk -v tt="$tmp_tbl" -f etl_explode
}
function etl_explode_extra_tbls_using_coroutine { # PRIVATE
  grep '#explode' <<<"$working_fields" | etl_explode_coroutine
}
function etl_process_tbls { # PRIVATE
  grep -E -o '#(include|append|sync(_no_update)?) [^#]+' "$ETL_TBL_TEMP_FILE" | awk '
function cc_ws(value, sep, new) {return (value=="") ? new : value sep new}
function tail2() {ret=""; for (i=2; i<=NF; i++) ret=cc_ws(ret," ",$i); return ret}
BEGIN {printf "cat <(echo)"} 
/^#include/ {printf "%s", " $ETL_EXT_DIR/"$2} 
/^#append/ {printf "%s", " <(echo \x22"tail2()"\x22)";} 
/^#sync/ {printf "%s", " <(etl_sync_tbl "$2")"}' | . /dev/stdin
}
function etl_run { # PRIVATE
  #setup files
  ETL_TBL_TEMP_FILE="$(mktemp)"; add_file_cleanup "$ETL_TBL_TEMP_FILE"
  TEMP_FILE="$(mktemp)"; add_file_cleanup "$TEMP_FILE"
  COROUTINE_FILE="$(mktemp)"; add_file_cleanup "$COROUTINE_FILE"

  # prep variables  
  sed 's/--.*$//' "$ETL_EXT_DIR/$ext_opt" >"$ETL_TBL_TEMP_FILE" # handle fifos; -- are real comments
  tmp_tbl=$(grep -Em1 '^CREATE (OR REPLACE )?(TEMPORARY )?TABLE' "$ETL_TBL_TEMP_FILE" | sed -r 's/^.* TABLE +([^ (]+)([( ].*)?$/\1/')
  ingest_fields=$(grep -E '#(map|ingest|unique)' "$ETL_TBL_TEMP_FILE" | grep -E -v '#(key|ignore|include|append)' | awk '{print $1}' | paste -sd',')
  all_directives='#(sync(_no_update)?|mode|l?join|where|append|include|ignore|ingest|key|unique|explode_[^ ]+|(map|generate|pivot)(_[^ ]+)?) '
  working_fields=$(grep -E "$all_directives" "$ETL_TBL_TEMP_FILE" | sed -r 's/^ +//;s/ +/ /g;s/^([^# ]+ )[^#]*/\1/;s/(#[^ ]+ )/\1  /' | awk '/^[^#]/ {gsub(/ '"$all_directives"'/, "\n"$1"&", $0)} /^[#]/ {gsub(/'"$all_directives"'/, "\n&", $0)} 1' | grep "#")

  # run tests
  cat >"$TEMP_FILE" # include the previous pipe's data... then test it
  [ -s "$TEMP_FILE" ] || case "$ETL_EXT_ERR_ON_EMPTY" in 0) : ;; 1) echo >&2 "[WARNING] Empty input: $base_filename.etl-$ext_opt"; return 0 ;; *) return 0 ;; esac
  awk 'NF {exit $1 !~ /^[(#]/}' || { echo >&2 "Invalid starting .etl line. Must be an INSERT row or a .batch directive"; return 1; }

  # execute
  if [ -z "$1" ] ; then # use_coroutine
    etl_populate_tmp_tbl
    echo '#RESET'
    etl_explode_extra_tbls_using_sql
    etl_process_tbls
  else 
    vclod_op "etlsql_coroutine.$1" |&  # TODO: pass ext_opt from env?
    etl_populate_tmp_tbl | vclod_op b.batch | while read l ; do print -p "$l" ; done
    etl_explode_extra_tbls_using_coroutine
    etl_process_tbls | while read l ; do print -p "$l" ; done
    print -p "quit" ; wait
  fi
}
